{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn\n",
    "!pip uninstall -y seaborn matplotlib\n",
    "!pip install seaborn==0.13.2 matplotlib==3.8.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data & Create Buckets & Run Model to Predict Bucket of Score Success of Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Detected duplicate quantile edges — applying small jitter for stability...\n",
      "\n",
      "Bucket distribution:\n",
      "score_bucket\n",
      "Low       0.333\n",
      "Medium    0.333\n",
      "High      0.333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Score cutoffs for each bucket:\n",
      "0.333333    1.0\n",
      "0.666667    1.0\n",
      "Name: score, dtype: float64\n",
      "\n",
      "Split sizes -> Train: 41106, Val: 13702, Test: 13703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyho/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/emilyho/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "Accuracy: 0.395 | Balanced Accuracy: 0.395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.43      0.47      0.45      4574\n",
      "         Low       0.36      0.32      0.34      4563\n",
      "      Medium       0.40      0.39      0.39      4565\n",
      "\n",
      "    accuracy                           0.39     13702\n",
      "   macro avg       0.39      0.39      0.39     13702\n",
      "weighted avg       0.39      0.39      0.39     13702\n",
      "\n",
      "Confusion matrix:\n",
      "            pred_Low  pred_Med  pred_High\n",
      "true_Low       1481      1527       1555\n",
      "true_Med       1445      1770       1350\n",
      "true_High      1239      1175       2160\n",
      "\n",
      "Test Results:\n",
      "Accuracy: 0.399 | Balanced Accuracy: 0.399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.44      0.48      0.46      4574\n",
      "         Low       0.37      0.34      0.35      4563\n",
      "      Medium       0.39      0.38      0.38      4566\n",
      "\n",
      "    accuracy                           0.40     13703\n",
      "   macro avg       0.40      0.40      0.40     13703\n",
      "weighted avg       0.40      0.40      0.40     13703\n",
      "\n",
      "Confusion matrix:\n",
      "            pred_Low  pred_Med  pred_High\n",
      "true_Low       1547      1588       1428\n",
      "true_Med       1416      1717       1433\n",
      "true_High      1227      1143       2204\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv\", low_memory=False)\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"score\"]).reset_index(drop=True)\n",
    "\n",
    "# df_careeradvice['score'].hist(bins=8)\n",
    "# plt.title('Histogram of score Column') \n",
    "# plt.xlabel('score') \n",
    "# plt.ylabel('Frequency') \n",
    "# plt.show() \n",
    "\n",
    "# df_careeradvice['log_score'] = np.log1p(df_careeradvice['score']) \n",
    "# df_careeradvice['log_score'].hist(bins=8)\n",
    "# plt.title('Histogram of log_score Column') \n",
    "# plt.xlabel('log_score') \n",
    "# plt.ylabel('Frequency') \n",
    "# plt.show()\n",
    "\n",
    "# bins = [0, 20, 150, np.inf] \n",
    "# labels = [\"Low\", \"Medium\", \"High\"]\n",
    "# df[\"score_bucket\"] = pd.cut(df[\"score\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"score\"]).reset_index(drop=True)\n",
    "\n",
    "# Try to create 3 balanced buckets\n",
    "try:\n",
    "    df[\"score_bucket\"] = pd.qcut(\n",
    "        df[\"score\"],\n",
    "        q=3,\n",
    "        labels=[\"Low\", \"Medium\", \"High\"],\n",
    "        duplicates=\"drop\"\n",
    "    )\n",
    "\n",
    "    if df[\"score_bucket\"].nunique() < 3:\n",
    "        raise ValueError(\"Fewer than 3 buckets created (duplicate quantile edges)\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"⚠️ Detected duplicate quantile edges — applying small jitter for stability...\")\n",
    "    rng = np.random.default_rng(42)\n",
    "    df[\"score_jitter\"] = df[\"score\"] + rng.uniform(0, 1e-6, len(df))\n",
    "\n",
    "    df[\"score_bucket\"] = pd.qcut(\n",
    "        df[\"score_jitter\"],\n",
    "        q=3,\n",
    "        labels=[\"Low\", \"Medium\", \"High\"],\n",
    "        duplicates=\"drop\"\n",
    "    )\n",
    "\n",
    "# Check distribution\n",
    "print(\"\\nBucket distribution:\")\n",
    "print(df[\"score_bucket\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Optional: print the quantile cutoffs\n",
    "cutoffs = df[\"score\"].quantile([1/3, 2/3])\n",
    "print(\"\\nScore cutoffs for each bucket:\")\n",
    "print(cutoffs)\n",
    "\n",
    "\n",
    "\n",
    "# ===== 3) Minimal text cleaning + combine =====\n",
    "def clean_text(t):\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", t)   # remove URLs\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)               # keep alnum + space\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "df[\"title\"] = df[\"title\"].apply(clean_text)\n",
    "df[\"text\"]  = df[\"text\"].apply(clean_text)\n",
    "df = df[(df[\"title\"] != \"\") & (df[\"text\"] != \"\")].reset_index(drop=True)\n",
    "\n",
    "df[\"combined\"] = (df[\"title\"] + \" \" + df[\"text\"]).str.strip()\n",
    "\n",
    "# ===== 4) Stratified split: 60 / 20 / 20 =====\n",
    "y = df[\"score_bucket\"]\n",
    "X = df[\"combined\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit sizes -> Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "# ===== 5) Text vectorization (title+text) =====\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_val_vec   = tfidf.transform(X_val)\n",
    "X_test_vec  = tfidf.transform(X_test)\n",
    "\n",
    "# ===== 6) Train classifier =====\n",
    "# Imbalance is OK; if you want a small boost to minority classes, set class_weight=\"balanced\"\n",
    "clf = LogisticRegression(max_iter=2000, n_jobs=-1, random_state=42)  # class_weight=None (imbalanced)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# ===== 7) Evaluate =====\n",
    "def evaluate(name, Xv, yv):\n",
    "    pred = clf.predict(Xv)\n",
    "    acc = accuracy_score(yv, pred)\n",
    "    bal = balanced_accuracy_score(yv, pred)\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Balanced Accuracy: {bal:.3f}\")\n",
    "    print(classification_report(yv, pred))\n",
    "    cm = confusion_matrix(yv, pred, labels=[\"Low\",\"Medium\",\"High\"])\n",
    "    cm_df = pd.DataFrame(cm, index=[\"true_Low\",\"true_Med\",\"true_High\"],\n",
    "                            columns=[\"pred_Low\",\"pred_Med\",\"pred_High\"])\n",
    "    print(\"Confusion matrix:\\n\", cm_df)\n",
    "\n",
    "evaluate(\"Validation\", X_val_vec, y_val)\n",
    "evaluate(\"Test\",        X_test_vec, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation — Acc: 0.394 | BalAcc: 0.394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High      0.432     0.456     0.444      4568\n",
      "         Low      0.359     0.328     0.343      4567\n",
      "      Medium      0.386     0.399     0.392      4567\n",
      "\n",
      "    accuracy                          0.394     13702\n",
      "   macro avg      0.392     0.394     0.393     13702\n",
      "weighted avg      0.392     0.394     0.393     13702\n",
      "\n",
      "Confusion matrix:\n",
      "            pred_Low  pred_Med  pred_High\n",
      "true_Low       1497      1616       1454\n",
      "true_Med       1469      1821       1277\n",
      "true_High      1208      1279       2081\n",
      "\n",
      "Test — Acc: 0.388 | BalAcc: 0.388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High      0.429     0.459     0.443      4567\n",
      "         Low      0.356     0.332     0.344      4568\n",
      "      Medium      0.375     0.373     0.374      4568\n",
      "\n",
      "    accuracy                          0.388     13703\n",
      "   macro avg      0.387     0.388     0.387     13703\n",
      "weighted avg      0.387     0.388     0.387     13703\n",
      "\n",
      "Confusion matrix:\n",
      "            pred_Low  pred_Med  pred_High\n",
      "true_Low       1517      1637       1414\n",
      "true_Med       1479      1706       1383\n",
      "true_High      1263      1206       2098\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# ===== 0) Start from your df_careeradvice =====\n",
    "try:\n",
    "    df = df_careeradvice.copy()\n",
    "except NameError:\n",
    "    df = pd.read_csv(\"./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv\", low_memory=False)\n",
    "\n",
    "# ===== 1) Clean + labels (3 tertiles on log_score with jitter) =====\n",
    "def clean_text(t):\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", t)\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "df = df.dropna(subset=[\"title\",\"text\",\"score\"]).copy()\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"score\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"title\"] = df[\"title\"].apply(clean_text)\n",
    "df[\"text\"]  = df[\"text\"].apply(clean_text)\n",
    "df = df[(df[\"title\"]!=\"\") & (df[\"text\"]!=\"\")].reset_index(drop=True)\n",
    "\n",
    "# tertiles on log1p(score) with tiny jitter to avoid duplicate edges\n",
    "log_s = np.log1p(df[\"score\"].astype(float))\n",
    "log_s_jit = log_s + np.random.uniform(0, 1e-6, size=len(df))\n",
    "df[\"score_bucket\"] = pd.qcut(log_s_jit, q=3, labels=[\"Low\",\"Medium\",\"High\"])\n",
    "y = df[\"score_bucket\"]\n",
    "\n",
    "# ===== 2) Split =====\n",
    "X_title, X_text = df[\"title\"], df[\"text\"]\n",
    "Xtr_t, Xtmp_t, y_tr, y_tmp, Xtr_x, Xtmp_x = train_test_split(\n",
    "    X_title, y, X_text, test_size=0.40, random_state=42, stratify=y\n",
    ")\n",
    "Xva_t, Xte_t, y_va, y_te, Xva_x, Xte_x = train_test_split(\n",
    "    Xtmp_t, y_tmp, Xtmp_x, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# ===== 3) Vectorizers =====\n",
    "# Title: word 1–2 grams (smaller vocab) — will be upweighted\n",
    "tfidf_title = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=15000)\n",
    "# Body: word 1–2 grams (larger vocab)\n",
    "tfidf_body  = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=30000)\n",
    "# Char n-grams on combined title+text\n",
    "tfidf_char  = TfidfVectorizer(analyzer=\"char\", ngram_range=(3,5), min_df=5, max_features=20000)\n",
    "\n",
    "# Fit on train only\n",
    "Xtr_title = tfidf_title.fit_transform(Xtr_t)\n",
    "Xtr_body  = tfidf_body.fit_transform(Xtr_x)\n",
    "Xtr_char  = tfidf_char.fit_transform((Xtr_t + \" \" + Xtr_x))\n",
    "\n",
    "# Transform val/test\n",
    "Xva_title = tfidf_title.transform(Xva_t)\n",
    "Xva_body  = tfidf_body.transform(Xva_x)\n",
    "Xva_char  = tfidf_char.transform((Xva_t + \" \" + Xva_x))\n",
    "Xte_title = tfidf_title.transform(Xte_t)\n",
    "Xte_body  = tfidf_body.transform(Xte_x)\n",
    "Xte_char  = tfidf_char.transform((Xte_t + \" \" + Xte_x))\n",
    "\n",
    "# ===== 4) Upweight title features =====\n",
    "TITLE_WEIGHT = 2.0\n",
    "Xtr_title = Xtr_title.multiply(TITLE_WEIGHT)\n",
    "Xva_title = Xva_title.multiply(TITLE_WEIGHT)\n",
    "Xte_title = Xte_title.multiply(TITLE_WEIGHT)\n",
    "\n",
    "# Stack: [title_words | body_words | char_ngrams]\n",
    "from scipy.sparse import csr_matrix\n",
    "Xtr = hstack([Xtr_title, Xtr_body, Xtr_char], format=\"csr\")\n",
    "Xva = hstack([Xva_title, Xva_body, Xva_char], format=\"csr\")\n",
    "Xte = hstack([Xte_title, Xte_body, Xte_char], format=\"csr\")\n",
    "\n",
    "# Optional: l2 normalize rows (helps SVM a bit)\n",
    "Xtr = normalize(Xtr, copy=False)\n",
    "Xva = normalize(Xva, copy=False)\n",
    "Xte = normalize(Xte, copy=False)\n",
    "\n",
    "# ===== 5) Model: Linear SVM with class weighting =====\n",
    "clf = LinearSVC(class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(Xtr, y_tr)\n",
    "\n",
    "def evaluate(name, X, y_true):\n",
    "    pred = clf.predict(X)\n",
    "    acc  = accuracy_score(y_true, pred)\n",
    "    bacc = balanced_accuracy_score(y_true, pred)\n",
    "    print(f\"\\n{name} — Acc: {acc:.3f} | BalAcc: {bacc:.3f}\")\n",
    "    print(classification_report(y_true, pred, digits=3))\n",
    "    cm = confusion_matrix(y_true, pred, labels=[\"Low\",\"Medium\",\"High\"])\n",
    "    print(\"Confusion matrix:\\n\", pd.DataFrame(cm,\n",
    "          index=[\"true_Low\",\"true_Med\",\"true_High\"],\n",
    "          columns=[\"pred_Low\",\"pred_Med\",\"pred_High\"]))\n",
    "\n",
    "evaluate(\"Validation\", Xva, y_va)\n",
    "evaluate(\"Test\",        Xte, y_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket distribution: {'Low': 0.333, 'Medium': 0.333, 'High': 0.333}\n",
      "Split sizes -> Train: 41125, Val: 13708, Test: 13709\n",
      "\n",
      "Validation Results:\n",
      "Accuracy: 0.383 | Balanced Accuracy: 0.383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High      0.418     0.439     0.428      4570\n",
      "         Low      0.353     0.343     0.348      4569\n",
      "      Medium      0.377     0.369     0.373      4569\n",
      "\n",
      "    accuracy                          0.383     13708\n",
      "   macro avg      0.382     0.383     0.383     13708\n",
      "weighted avg      0.382     0.383     0.383     13708\n",
      "\n",
      "Confusion matrix:\n",
      "            pred_Low  pred_Med  pred_High\n",
      "true_Low       1565      1552       1452\n",
      "true_Med       1539      1684       1346\n",
      "true_High      1328      1236       2006\n",
      "\n",
      "Test Results:\n",
      "Accuracy: 0.375 | Balanced Accuracy: 0.375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High      0.405     0.421     0.413      4569\n",
      "         Low      0.357     0.343     0.350      4570\n",
      "      Medium      0.362     0.362     0.362      4570\n",
      "\n",
      "    accuracy                          0.375     13709\n",
      "   macro avg      0.375     0.375     0.375     13709\n",
      "weighted avg      0.375     0.375     0.375     13709\n",
      "\n",
      "Confusion matrix:\n",
      "            pred_Low  pred_Med  pred_High\n",
      "true_Low       1568      1569       1433\n",
      "true_Med       1524      1653       1393\n",
      "true_High      1305      1340       1924\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# r/careeradvice — Predict post \"success bucket\" (Low/Med/High)\n",
    "# with sentiment, readability, metadata, and TF-IDF text features\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd, numpy as np, re, warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---------- 1) Load data ----------\n",
    "df = pd.read_csv(\"./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv\", low_memory=False)\n",
    "df = df[df.get(\"subreddit\", \"\").str.lower().eq(\"careeradvice\") | ~df.get(\"subreddit\", \"\").notna()]  # optional\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "df[\"num_comments\"] = pd.to_numeric(df.get(\"num_comments\", np.nan), errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"score\", \"title\", \"text\"]).reset_index(drop=True)\n",
    "\n",
    "# ---------- 2) Clean text ----------\n",
    "def clean_text(t):\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", t)\n",
    "    t = re.sub(r\"[^a-z0-9\\s?!.,:;']\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "df[\"title\"] = df[\"title\"].apply(clean_text)\n",
    "df[\"text\"]  = df[\"text\"].apply(clean_text)\n",
    "df = df[(df[\"title\"] != \"\") & (df[\"text\"] != \"\")].reset_index(drop=True)\n",
    "\n",
    "# ---------- 3) Success buckets (balanced tertiles on log(score)) ----------\n",
    "df[\"log_score\"] = np.log1p(df[\"score\"])\n",
    "df[\"log_score_jit\"] = df[\"log_score\"] + np.random.uniform(0, 1e-6, len(df))\n",
    "df[\"bucket\"] = pd.qcut(df[\"log_score_jit\"], q=3, labels=[\"Low\",\"Medium\",\"High\"], duplicates=\"drop\")\n",
    "print(\"Bucket distribution:\", df[\"bucket\"].value_counts(normalize=True).round(3).to_dict())\n",
    "\n",
    "# ---------- 4) Sentiment + simple metadata ----------\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df[\"sent_title\"] = df[\"title\"].apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "df[\"sent_text\"]  = df[\"text\"].apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "df[\"title_len\"]   = df[\"title\"].str.split().str.len()\n",
    "df[\"text_len\"]    = df[\"text\"].str.split().str.len()\n",
    "df[\"has_question\"] = df[\"title\"].str.contains(r\"\\?\").astype(int)\n",
    "df[\"exclaims\"]     = df[\"title\"].str.count(\"!\")\n",
    "df[\"caps_ratio\"]   = df[\"title\"].apply(lambda s: sum(ch.isupper() for ch in s) / max(len(s),1))\n",
    "df[\"hour\"] = 0\n",
    "df[\"dow\"]  = 0\n",
    "\n",
    "# ---------- 5) Text for vectorization ----------\n",
    "df[\"combined\"] = (df[\"title\"] + \" \" + df[\"text\"]).str.strip()\n",
    "\n",
    "# ---------- 6) Train/Val/Test split ----------\n",
    "y = df[\"bucket\"]\n",
    "df_train, df_temp, y_train, y_temp = train_test_split(df, y, test_size=0.4, random_state=42, stratify=y)\n",
    "df_val, df_test, y_val, y_test = train_test_split(df_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "print(f\"Split sizes -> Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")\n",
    "\n",
    "# ---------- 7) TF-IDF vectorization ----------\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=20000)\n",
    "X_train_tfidf = tfidf.fit_transform(df_train[\"combined\"])\n",
    "X_val_tfidf   = tfidf.transform(df_val[\"combined\"])\n",
    "X_test_tfidf  = tfidf.transform(df_test[\"combined\"])\n",
    "\n",
    "# ---------- 8) Numeric features ----------\n",
    "num_cols = [\"sent_title\",\"sent_text\",\"title_len\",\"text_len\",\"has_question\",\"exclaims\",\"caps_ratio\",\"hour\",\"dow\"]\n",
    "\n",
    "# Make sure all numeric values are finite\n",
    "for c in num_cols:\n",
    "    df_train[c] = pd.to_numeric(df_train[c], errors=\"coerce\")\n",
    "    df_val[c]   = pd.to_numeric(df_val[c], errors=\"coerce\")\n",
    "    df_test[c]  = pd.to_numeric(df_test[c], errors=\"coerce\")\n",
    "\n",
    "df_train[num_cols] = df_train[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "df_val[num_cols]   = df_val[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "df_test[num_cols]  = df_test[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "scaler = StandardScaler().fit(df_train[num_cols])\n",
    "X_train_num = scaler.transform(df_train[num_cols])\n",
    "X_val_num   = scaler.transform(df_val[num_cols])\n",
    "X_test_num  = scaler.transform(df_test[num_cols])\n",
    "\n",
    "# Ensure no NaNs left\n",
    "X_train_num = np.nan_to_num(X_train_num, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_val_num   = np.nan_to_num(X_val_num, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test_num  = np.nan_to_num(X_test_num, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Combine TF-IDF + numeric\n",
    "X_train = hstack([X_train_tfidf, csr_matrix(X_train_num)], format=\"csr\")\n",
    "X_val   = hstack([X_val_tfidf,   csr_matrix(X_val_num)],   format=\"csr\")\n",
    "X_test  = hstack([X_test_tfidf,  csr_matrix(X_test_num)],  format=\"csr\")\n",
    "\n",
    "# ---------- 9) Train model ----------\n",
    "model = LinearSVC(class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---------- 10) Evaluate ----------\n",
    "def evaluate(name, X, y_true):\n",
    "    preds = model.predict(X)\n",
    "    acc  = accuracy_score(y_true, preds)\n",
    "    bacc = balanced_accuracy_score(y_true, preds)\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Balanced Accuracy: {bacc:.3f}\")\n",
    "    print(classification_report(y_true, preds, digits=3))\n",
    "    cm = confusion_matrix(y_true, preds, labels=[\"Low\",\"Medium\",\"High\"])\n",
    "    print(\"Confusion matrix:\\n\", pd.DataFrame(\n",
    "        cm, index=[\"true_Low\",\"true_Med\",\"true_High\"], columns=[\"pred_Low\",\"pred_Med\",\"pred_High\"]\n",
    "    ))\n",
    "\n",
    "evaluate(\"Validation\", X_val, y_val)\n",
    "evaluate(\"Test\", X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket distribution:\n",
      "bucket\n",
      "Low       0.333\n",
      "High      0.333\n",
      "Medium    0.333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Split sizes: train=41127, val=13709, test=13710\n",
      "\n",
      "Validation Results\n",
      "Accuracy: 0.402 | Balanced Accuracy: 0.402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High      0.445     0.495     0.468      4570\n",
      "         Low      0.361     0.321     0.340      4570\n",
      "      Medium      0.391     0.390     0.390      4569\n",
      "\n",
      "    accuracy                          0.402     13709\n",
      "   macro avg      0.399     0.402     0.399     13709\n",
      "weighted avg      0.399     0.402     0.399     13709\n",
      "\n",
      "           pred_Low  pred_Med  pred_High\n",
      "true_Low       1467      1629       1474\n",
      "true_Med       1438      1780       1351\n",
      "true_High      1160      1149       2261\n",
      "\n",
      "Test Results\n",
      "Accuracy: 0.404 | Balanced Accuracy: 0.404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High      0.438     0.486     0.461      4570\n",
      "         Low      0.369     0.334     0.350      4570\n",
      "      Medium      0.397     0.391     0.394      4570\n",
      "\n",
      "    accuracy                          0.404     13710\n",
      "   macro avg      0.401     0.404     0.402     13710\n",
      "weighted avg      0.401     0.404     0.402     13710\n",
      "\n",
      "           pred_Low  pred_Med  pred_High\n",
      "true_Low       1525      1551       1494\n",
      "true_Med       1430      1789       1351\n",
      "true_High      1181      1168       2221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(\"./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv\", low_memory=False)\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "df[\"num_comments\"] = pd.to_numeric(df.get(\"num_comments\", np.nan), errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"score\", \"title\", \"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Simple text cleaning\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s?!.,:;']\", \" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "df[\"title\"] = df[\"title\"].apply(clean_text)\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "df = df[(df[\"title\"] != \"\") & (df[\"text\"] != \"\")].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df[\"log_score\"] = np.log1p(df[\"score\"])\n",
    "df[\"log_score_jitter\"] = df[\"log_score\"] + np.random.uniform(0, 1e-6, len(df))\n",
    "df[\"bucket\"] = pd.qcut(df[\"log_score_jitter\"], q=3, labels=[\"Low\", \"Medium\", \"High\"], duplicates=\"drop\")\n",
    "\n",
    "print(\"Bucket distribution:\")\n",
    "print(df[\"bucket\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Add sentiment + basic metadata\n",
    "# ------------------------------------------------\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df[\"sent_title\"] = df[\"title\"].apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "df[\"sent_text\"] = df[\"text\"].apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "df[\"title_len\"] = df[\"title\"].str.split().str.len()\n",
    "df[\"text_len\"] = df[\"text\"].str.split().str.len()\n",
    "df[\"has_question\"] = df[\"title\"].str.contains(r\"\\?\").astype(int)\n",
    "df[\"exclaims\"] = df[\"title\"].str.count(\"!\")\n",
    "df[\"caps_ratio\"] = df[\"title\"].apply(lambda s: sum(ch.isupper() for ch in s) / max(len(s), 1))\n",
    "df[\"combined\"] = (df[\"title\"] + \" \" + df[\"text\"]).str.strip()\n",
    "y = df[\"bucket\"]\n",
    "df_train, df_temp, y_train, y_temp = train_test_split(df, y, test_size=0.4, random_state=42, stratify=y)\n",
    "df_val, df_test, y_val, y_test = train_test_split(df_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "print(f\"\\nSplit sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=20000)\n",
    "X_train_tfidf = tfidf.fit_transform(df_train[\"combined\"])\n",
    "X_val_tfidf = tfidf.transform(df_val[\"combined\"])\n",
    "X_test_tfidf = tfidf.transform(df_test[\"combined\"])\n",
    "num_cols = [\"sent_title\", \"sent_text\", \"title_len\", \"text_len\", \"has_question\", \"exclaims\", \"caps_ratio\"]\n",
    "\n",
    "for c in num_cols:\n",
    "    df_train[c] = pd.to_numeric(df_train[c], errors=\"coerce\")\n",
    "    df_val[c] = pd.to_numeric(df_val[c], errors=\"coerce\")\n",
    "    df_test[c] = pd.to_numeric(df_test[c], errors=\"coerce\")\n",
    "\n",
    "for d in [df_train, df_val, df_test]:\n",
    "    d[num_cols] = d[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "scaler = StandardScaler().fit(df_train[num_cols])\n",
    "X_train_num = scaler.transform(df_train[num_cols])\n",
    "X_val_num = scaler.transform(df_val[num_cols])\n",
    "X_test_num = scaler.transform(df_test[num_cols])\n",
    "\n",
    "X_train = hstack([X_train_tfidf, csr_matrix(X_train_num)], format=\"csr\")\n",
    "X_val = hstack([X_val_tfidf, csr_matrix(X_val_num)], format=\"csr\")\n",
    "X_test = hstack([X_test_tfidf, csr_matrix(X_test_num)], format=\"csr\")\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "def evaluate(name, X, y_true):\n",
    "    preds = model.predict(X)\n",
    "    acc = accuracy_score(y_true, preds)\n",
    "    bacc = balanced_accuracy_score(y_true, preds)\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Balanced Accuracy: {bacc:.3f}\")\n",
    "    print(classification_report(y_true, preds, digits=3))\n",
    "    cm = confusion_matrix(y_true, preds, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "    print(pd.DataFrame(cm,\n",
    "        index=[\"true_Low\", \"true_Med\", \"true_High\"],\n",
    "        columns=[\"pred_Low\", \"pred_Med\", \"pred_High\"]\n",
    "    ))\n",
    "\n",
    "evaluate(\"Validation\", X_val, y_val)\n",
    "evaluate(\"Test\", X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1286/1286 [32:25<00:00,  1.51s/it]   \n",
      "Batches: 100%|██████████| 429/429 [11:44<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 429/429 [13:03<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.45      0.56      0.50      4569\n",
      "         Low       0.37      0.29      0.33      4570\n",
      "      Medium       0.40      0.39      0.40      4570\n",
      "\n",
      "    accuracy                           0.41     13709\n",
      "   macro avg       0.41      0.41      0.41     13709\n",
      "weighted avg       0.41      0.41      0.41     13709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Use pretrained model (fast & small)\n",
    "bert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode text\n",
    "X_train_emb = bert.encode(df_train[\"combined\"].tolist(), show_progress_bar=True)\n",
    "X_val_emb   = bert.encode(df_val[\"combined\"].tolist(), show_progress_bar=True)\n",
    "X_test_emb  = bert.encode(df_test[\"combined\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Train logistic regression or SVM on these\n",
    "clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "clf.fit(X_train_emb, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_emb)\n",
    "print(classification_report(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "602039c487ccb8916c4ce42797e8a242a3fe8d1e182433a2fc68388a402f1cf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
