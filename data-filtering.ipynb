{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a813d055",
   "metadata": {},
   "source": [
    "CODE TO CHOOSE WHAT IS LABELED AS A GOOD POST AND A BAD POST\n",
    "\n",
    "Good post: Viral, score is high and interactions are high (top 10%)\n",
    "Bad post: Low-Performing, score is low and interactions are low (bottom 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c7823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc70609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_posts_by_performance(input_csv, output_dir=\"./filtered_data\", \n",
    "                                 top_percentile=90, bottom_percentile=10):\n",
    "    \"\"\"\n",
    "    Filter posts into 'viral' (high-performing) and 'low-performing' categories.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_csv : str\n",
    "        Path to the input CSV file\n",
    "    output_dir : str\n",
    "        Directory to save filtered CSVs\n",
    "    top_percentile : int\n",
    "        Percentile threshold for viral posts (default: 90 = top 10%)\n",
    "    bottom_percentile : int\n",
    "        Percentile threshold for low-performing posts (default: 10 = bottom 10%)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the data\n",
    "    print(f\"Loading data from {input_csv}...\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"Loaded {len(df)} posts\")\n",
    "    \n",
    "    # Clean and convert numeric columns\n",
    "    df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "    df[\"num_comments\"] = pd.to_numeric(df[\"num_comments\"], errors=\"coerce\")\n",
    "    \n",
    "    # Remove rows with missing values in key columns\n",
    "    df = df.dropna(subset=[\"score\", \"num_comments\"])\n",
    "    print(f\"After removing NaN values: {len(df)} posts\")\n",
    "    \n",
    "    # Calculate normalized engagement score (same as your popularity metric)\n",
    "    def minmax_norm(series):\n",
    "        smin, smax = series.min(), series.max()\n",
    "        if pd.isna(smin) or pd.isna(smax) or smax == smin:\n",
    "            return pd.Series([0.5] * len(series), index=series.index)\n",
    "        return (series - smin) / (smax - smin)\n",
    "    \n",
    "    df[\"score_norm\"] = minmax_norm(df[\"score\"])\n",
    "    df[\"comments_norm\"] = minmax_norm(df[\"num_comments\"])\n",
    "    df[\"engagement_score\"] = 0.5 * df[\"score_norm\"] + 0.5 * df[\"comments_norm\"]\n",
    "    \n",
    "    # Calculate percentile thresholds\n",
    "    viral_threshold = np.percentile(df[\"engagement_score\"], top_percentile)\n",
    "    low_threshold = np.percentile(df[\"engagement_score\"], bottom_percentile)\n",
    "    \n",
    "    # Filter viral posts (top performers)\n",
    "    viral_posts = df[df[\"engagement_score\"] >= viral_threshold].copy()\n",
    "    viral_posts = viral_posts.sort_values(\"engagement_score\", ascending=False)\n",
    "    \n",
    "    # Filter low-performing posts (bottom performers)\n",
    "    low_posts = df[df[\"engagement_score\"] <= low_threshold].copy()\n",
    "    low_posts = low_posts.sort_values(\"engagement_score\", ascending=True)\n",
    "    \n",
    "    # Generate output filenames\n",
    "    base_name = os.path.splitext(os.path.basename(input_csv))[0]\n",
    "    viral_output = os.path.join(output_dir, f\"{base_name}_viral.csv\")\n",
    "    low_output = os.path.join(output_dir, f\"{base_name}_low_performing.csv\")\n",
    "    \n",
    "    # Save filtered datasets\n",
    "    viral_posts.to_csv(viral_output, index=False)\n",
    "    low_posts.to_csv(low_output, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FILTERING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOriginal dataset: {len(df)} posts\")\n",
    "    print(f\"\\nEngagement score range: {df['engagement_score'].min():.4f} to {df['engagement_score'].max():.4f}\")\n",
    "    print(f\"Viral threshold (top {100-top_percentile}%): {viral_threshold:.4f}\")\n",
    "    print(f\"Low-performing threshold (bottom {bottom_percentile}%): {low_threshold:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”¥ VIRAL POSTS (Top {100-top_percentile}%): {len(viral_posts)} posts\")\n",
    "    print(f\"   Score range: {viral_posts['score'].min():.0f} to {viral_posts['score'].max():.0f}\")\n",
    "    print(f\"   Comments range: {viral_posts['num_comments'].min():.0f} to {viral_posts['num_comments'].max():.0f}\")\n",
    "    print(f\"   Engagement score range: {viral_posts['engagement_score'].min():.4f} to {viral_posts['engagement_score'].max():.4f}\")\n",
    "    print(f\"   Saved to: {viral_output}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‰ LOW-PERFORMING POSTS (Bottom {bottom_percentile}%): {len(low_posts)} posts\")\n",
    "    print(f\"   Score range: {low_posts['score'].min():.0f} to {low_posts['score'].max():.0f}\")\n",
    "    print(f\"   Comments range: {low_posts['num_comments'].min():.0f} to {low_posts['num_comments'].max():.0f}\")\n",
    "    print(f\"   Engagement score range: {low_posts['engagement_score'].min():.4f} to {low_posts['engagement_score'].max():.4f}\")\n",
    "    print(f\"   Saved to: {low_output}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Show sample posts from each category\n",
    "    if \"title\" in viral_posts.columns:\n",
    "        print(\"\\nðŸ“Š SAMPLE VIRAL POSTS:\")\n",
    "        print(viral_posts[[\"title\", \"score\", \"num_comments\", \"engagement_score\"]].head(3).to_string(index=False))\n",
    "    \n",
    "    if \"title\" in low_posts.columns:\n",
    "        print(\"\\nðŸ“Š SAMPLE LOW-PERFORMING POSTS:\")\n",
    "        print(low_posts[[\"title\", \"score\", \"num_comments\", \"engagement_score\"]].head(3).to_string(index=False))\n",
    "    \n",
    "    return viral_posts, low_posts, df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694f9e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automatic filtering...\n",
      "Searching for CSV files...\n",
      "Found 1 CSV file(s):\n",
      "  - ./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv\n",
      "\n",
      "Processing: ./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv\n",
      "Loading data from ./updated_data_rp3/data/careeradvice/combined_careeradvice_raw.csv...\n",
      "Loaded 68692 posts\n",
      "After removing NaN values: 68684 posts\n",
      "\n",
      "============================================================\n",
      "FILTERING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Original dataset: 68684 posts\n",
      "\n",
      "Engagement score range: 0.0000 to 0.6570\n",
      "Viral threshold (top 10%): 0.0019\n",
      "Low-performing threshold (bottom 10%): 0.0000\n",
      "\n",
      "ðŸ”¥ VIRAL POSTS (Top 10%): 6962 posts\n",
      "   Score range: 0 to 17044\n",
      "   Comments range: 1 to 3169\n",
      "   Engagement score range: 0.0019 to 0.6570\n",
      "   Saved to: ./filtered_data/combined_careeradvice_raw_viral.csv\n",
      "\n",
      "ðŸ“‰ LOW-PERFORMING POSTS (Bottom 10%): 25306 posts\n",
      "   Score range: 0 to 1\n",
      "   Comments range: 0 to 0\n",
      "   Engagement score range: 0.0000 to 0.0000\n",
      "   Saved to: ./filtered_data/combined_careeradvice_raw_low_performing.csv\n",
      "\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š SAMPLE VIRAL POSTS:\n",
      "                                                                                                    title   score  num_comments  engagement_score\n",
      "I got a raise after I started leaving exactly at 5pm and my boss is acting like I've \"stepped up my game\" 17044.0         995.0          0.656990\n",
      "                                             How were you able to land a high salary job of $70k or more?  1877.0        3169.0          0.555063\n",
      "                     My boss confronted me about only working 7 hours and 45 minutes a day, what do I do?  3382.0        2314.0          0.464313\n",
      "\n",
      "ðŸ“Š SAMPLE LOW-PERFORMING POSTS:\n",
      "                                                 title  score  num_comments  engagement_score\n",
      "                                  Does it work or not?    0.0           0.0               0.0\n",
      "                    Event/Wedding Planners please read    0.0           0.0               0.0\n",
      "Feeling incredible anxiety and guilt about not working    0.0           0.0               0.0\n",
      "\n",
      "âœ… Filtering complete! Check the './filtered_data/' directory for results.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Automatically run when script is executed\n",
    "print(\"Starting automatic filtering...\")\n",
    "print(\"Searching for CSV files...\")\n",
    "\n",
    "data_dir = \"./updated_data_rp3/data/careeradvice/\"\n",
    "csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(f\"âŒ No CSV files found in {data_dir}\")\n",
    "    print(f\"Checking current directory for the folder...\")\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"âŒ Directory does not exist: {data_dir}\")\n",
    "        print(\"\\nPlease update the 'data_dir' variable with the correct path to your CSV file.\")\n",
    "    else:\n",
    "        print(f\"Directory exists but no CSV files found.\")\n",
    "        zip_files = glob.glob(os.path.join(data_dir, \"*.zip\"))\n",
    "        if zip_files:\n",
    "            print(f\"Found zip file(s): {zip_files}\")\n",
    "            print(\"Please unzip the file first.\")\n",
    "else:\n",
    "    print(f\"Found {len(csv_files)} CSV file(s):\")\n",
    "    for f in csv_files:\n",
    "        print(f\"  - {f}\")\n",
    "    \n",
    "    # Use the first CSV file found\n",
    "    input_csv = csv_files[0]\n",
    "    print(f\"\\nProcessing: {input_csv}\")\n",
    "    \n",
    "    viral, low, all_data = filter_posts_by_performance(\n",
    "        input_csv=input_csv,\n",
    "        output_dir=\"./filtered_data\",\n",
    "        top_percentile=90,  # Top 10% are viral\n",
    "        bottom_percentile=10  # Bottom 10% are low-performing\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Filtering complete! Check the './filtered_data/' directory for results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd7a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
